---
title: "Lista 04 de MCCD II"
author: "Emanuelle, Maria Luiza e Mariana Fleming"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(knitr)
```

# Questão 01

Gere amostras de tamanho $n = 10$ e $50$, e estime erro padrão e viés da média amostral como estimador da média populacional nas seguintes situações:  

a) $X \sim N(0, \sigma^2)$  
b) $X \sim \text{Gama}(2, 5)$  
c) Outra distribuição de sua escolha.  

Compare com o valor teórico nas três situações.

# Questão 02

Considere os seguintes estimadores para variância populacional:

$\hat{\sigma}^2_1 = \dfrac{1}{n - 1}\sum_{i=1}^n (x_i - \bar{x})^2$  
$\hat{\sigma}^2_2 = \dfrac{1}{n}\sum_{i=1}^n (x_i - \bar{x})^2$

Gere amostras de tamanho $n = 30$ e estime erro padrão e viés com estes estimadores da variância populacional nas seguintes situações:  

a) $X \sim N(0, \sigma^2)$  
b) $X \sim \text{Gama}(2, 5)$  
c) Outra distribuição de sua escolha.

# Questão 03

Implemente funções para calcular os intervalos de confiança bootstrap studentizado e BCa. Compare o resultado fornecido com o intervalo construído com as funções do pacote `boot`.

## Solução

**IC Bootstrap Studentizado**

O intervalo de confiança Bootstrap Studentizado é baseado na distribuição amostral de uma estatística studentizada gerada por reamostragem. O intervalo de $100(1 - \alpha)\%$ de confiança é dado por:

$$ \left[ \hat{\theta} - t^*_{1-\alpha/2} \hat{se}(\hat{\theta}); \hat{\theta} - t^*_{\alpha/2} \hat{se}(\hat{\theta}) \right] $$

### Passo a passo

1. Calcule $\hat{\theta}$.

2. Para cada réplica $b = 1, \dots, B$, gere uma amostra $x^{*(b)}$ por amostragem com reposição da amostra observada, calcule $\hat{\theta}^{(b)}$ e a estatística studentizada:

$$
t^{(b)} = \frac{\hat{\theta}^{(b)} - \hat{\theta}}{\hat{se}(\hat{\theta}^{(b)})}
$$

3. Calcule os quantis $t^*_{\alpha/2}$ e $t^*_{1-\alpha/2}$ a partir da amostra ordenada de $t^{(b)}$ e construa o intervalo de confiança.

### Implementação do código

```{r ex3-student}
ic_bootstrap_studentizado <- function(x, stat = mean, B = 1000, R = 200, alpha = 0.05) {
  n <- length(x)
  theta_chapeu <- stat(x)
  ep_chapeu <- sd(replicate(R, stat(sample(x, n, replace = TRUE))))
  
  t_boot <- numeric(B)
  for (b in 1:B) {
    x_estrela <- sample(x, n, replace = TRUE)
    theta_b <- stat(x_estrela)
    ep_b <- sd(replicate(R, stat(sample(x_estrela, n, replace = TRUE))))
    t_boot[b] <- (theta_b - theta_chapeu) / ep_b
  }
  
  t_quant <- quantile(t_boot, c(alpha / 2, 1 - alpha / 2))
  ic <- c(theta_chapeu - t_quant[2] * ep_chapeu,
          theta_chapeu - t_quant[1] * ep_chapeu)
  return(ic)
}
```

**IC Bootstrap BCa**

O intervalo de confiança BCa (Bias-Corrected and Accelerated) é uma versão modificada do intervalo percentílico que possui melhores propriedades teóricas e melhor desempenho. O intervalo BCa ajusta os quantis usuais por dois fatores: $\hat{z}_0$ (correção para viés) e $\hat{a}$ (aceleração/assimetria).

O intervalo de $100(1 - \alpha)\%$ de confiança BCa é dado pelos quantis empíricos $\hat{\theta}_{\alpha_1}$ e $\hat{\theta}_{\alpha_2}$ das réplicas bootstrap, onde $\alpha_1$ e $\alpha_2$ são os quantis ajustados:

$$
\alpha_1 = \Phi \left( \frac{\hat{z}_0 + \hat{z}_0 + z_{\alpha/2}}{1 - \hat{a}(\hat{z}_0 + z_{\alpha/2})} \right)
$$

$$
\alpha_2 = \Phi \left( \frac{\hat{z}_0 + \hat{z}_0 + z_{1-\alpha/2}}{1 - \hat{a}(\hat{z}_0 + z_{1-\alpha/2})} \right)
$$

onde $z_{\alpha} = \Phi^{-1}(\alpha)$ é o quantil da distribuição normal padrão.

### Passo a passo

1. Calcule $\hat{\theta}$.

2. Gere $B$ réplicas bootstrap $\hat{\theta}^{(b)}$.

3. Gere $n$ réplicas Jackknife $\hat{\theta}_{[-i]}$.

4. Calcule o fator de viés corrigido: $ \hat{z}_0 = \Phi^{-1} \left( \frac{1}{B} \sum_{b=1}^B I\{\hat{\theta}^{(b)} < \hat{\theta}\} \right) $.

5. Calcule o ajuste de assimetria utilizando as réplicas Jackknife:

$$
\hat{a} = \frac{\sum_{i=1}^n (\bar{\theta}_{[\cdot]} - \hat{\theta}_{[-i]})^3}{6(\sum_{i=1}^n (\bar{\theta}_{[\cdot]} - \hat{\theta}_{[-i]})^2)^{3/2}}
$$

onde $\bar{\theta}_{[\cdot]} = \frac{1}{n} \sum_{i=1}^n \hat{\theta}_{[-i]}$.

6. Calcule $\alpha_1$, $\alpha_2$ e os quantis empíricos $\hat{\theta}_{\alpha_1}$ e $\hat{\theta}_{\alpha_2}$ a partir da distribuição ordenada de $\hat{\theta}^{(b)}$.

### Implementação do código

```{r ex3-bca}
ic_bootstrap_bca <- function(x, stat = mean, B = 1000, alpha = 0.05) {
  n <- length(x)
  theta_chapeu <- stat(x)
  
  # bootstrap
  thetas <- replicate(B, stat(sample(x, n, replace = TRUE)))
  
  # jackknife
  jack <- sapply(1:n, function(i) stat(x[-i]))
  theta_barra <- mean(jack)
  
  # parâmetros BCa
  z0 <- qnorm(mean(thetas < theta_chapeu))
  a <- sum((theta_barra - jack)^3) / (6 * (sum((theta_barra - jack)^2))^(3/2))

  z_alfa <- qnorm(c(alpha / 2, 1 - alpha / 2))
  alfa <- pnorm(z0 + (z0 + z_alfa) / (1 - a * (z0 + z_alfa)))
  
  ic <- quantile(thetas, probs = alfa)
  
  return(ic)
}
```

**Comparação com o Pacote `boot`**

### Implementação do código

```{r ex3-boot}
library(boot)
set.seed(123456789)
x <- rnorm(30, mean = 5, sd = 2)

# necessário para "stud"

metricas_boot_student <- function(data, idx) {
  d <- data[idx]
  m <- mean(d)
  se <- sd(d) / sqrt(length(d))
  return(c(mean = m, se = se))
}

# retorna média e erro padrão
boot_obj <- boot(x, statistic = metricas_boot_student, R = 1000, sim = "ordinary", stype = "i")


ic_student <- ic_bootstrap_studentizado(x, stat = mean, B = 500, R = 100)
ic_bca <- ic_bootstrap_bca(x, stat = mean, B = 1000)

# funções do pacote
boot_student <- boot.ci(boot_obj, type = "stud")
boot_bca <- boot.ci(boot_obj, type = "bca")

resultado <- data.frame(
  Metodo = c("Studentizado (manual)",
             "Studentizado (pacote)",
             "BCa (manual)",
             "BCa (pacote)"),
  IC_Inferior = c(
    round(ic_student[1], 4),
    round(as.numeric(boot_student$student[,4]), 4),
    round(ic_bca[1], 4),
    round(boot_bca$bca[,4], 4)
  ),
  IC_Superior = c(
    round(ic_student[2], 4),
    round(as.numeric(boot_student$student[,5]), 4),
    round(ic_bca[2], 4),
    round(boot_bca$bca[,5], 4)
  )
)

kable(resultado)
```

Os resultados ficaram próximos, o que confirma que o código está performando bem.

# QUestão 04

Faça um estudo de Monte Carlo para comparar a probabilidade de cobertura dos intervalos de confiança bootstrap para a média populacional gerando amostras das distribuições Normal e Lognormal. Para as duas distribuições, utilize tamanhos amostrais iguais a 20, 50 e 150. Considere 4 métodos bootstrap de sua escolha para a obtenção dos intervalos de confiança e também compare com a probabilidade de cobertura do intervalo paramétrico com a $t$-Student.

# Questão 05

Compare os bootstraps paramétrico e não paramétrico na estimação do erro padrão de $\bar{X}$ para estimar $E[X]$ quando os dados são gerados da distribuição binomial negativa. No bootstrap paramétrico, assuma que os dados são oriundos da distribuição Poisson para avaliar o efeito da má especificação da distribuição populacional. Utilize 3 valores diferentes para tamanho amostral.

## Solução

O bootstrap não paramétrico estima a distribuição amostral reamostrando a partir da distribuição empírica (com reposição). Já o bootstrap paramétrico assume uma forma paramétrica e simula a partir dessa distribuição estimada.

### Passo a passo

1. Defina os parâmetros da simulação: a distribuição verdadeira (no caso, Binomial Negativa com $r=4$, $p=0.75$) e seus parâmetros, incluindo a variância e o erro padrão verdadeiro. Serão considerados três tamanhos amostrais: $n = 30, 100, 500$.

2. Para cada tamanho amostral e para cada uma das $M = 1000$ iterações, gere uma amostra da Binomial Negativa, calcule o erro padrão via bootstrap não paramétrico, reamostrando a própria amostra, além do erro padrão via bootstrap paramétrico assumindo incorretamente uma outra distribuição (no caso, Poisson).

3. Para cada $n$, guarde os erros padrão verdadeiros, e os estimados pelos métodos BNP e BP e compare.

### Implementação do código

```{r ex5}
M <- 1000
B <- 2000
tamanhos <- c(30, 100, 500) 

r <- 4 
p <- 0.75 

var_x <- r * (1 - p) / (p^2) 

# calcula o erro padrão verdadeiro de X barra
calcula_ep <- function(n) {
  sqrt(var_x / n)
}

ep <- list()

simulacao <- function(tamanho_amostral, M, B, r, p) {
  
  ep_np <- numeric(M) # não paramétrico
  ep_p <- numeric(M) # paramétrico
  
  ep_verdadeiro <- calcula_ep(tamanho_amostral)

  for (i in 1:M) {
    # geração da amostra real
    amostra <- rnbinom(tamanho_amostral, size = r, prob = p)
    
    # não paramétrico
    media_np <- replicate(B, {
      mean(sample(amostra, tamanho_amostral, replace = TRUE))
    })
    ep_np[i] <- sd(media_np)
    
    # paramétrico (mal especificado)
    lambda_chapeu <- mean(amostra)
    
    media_p <- replicate(B, {
      mean(rpois(tamanho_amostral, lambda = lambda_chapeu))
    })
    ep_p[i] <- sd(media_p)
  }
  
  return(data.frame(
    n = tamanho_amostral,
    EP_Verdadeiro = ep_verdadeiro,
    EP_NP = ep_np,
    EP_P = ep_p
  ))
  
}

set.seed(123456789)
for (n in tamanhos) {
  ep[[as.character(n)]] <- simulacao(n, M, B, r, p)
}


dados_plot <- data.frame()
for (n_str in names(ep)) {
  res <- ep[[n_str]]
  n <- res$n[1]  # apenas o valor de n (é constante dentro de cada data.frame)
  ep_real <- res$EP_Verdadeiro[1]
  
  df_np <- data.frame(
    n = factor(n),
    Metodo = "Não-Paramétrico",
    EP_Estimado = res$EP_NP,
    EP_Verdadeiro = ep_real
  )
  
  df_p <- data.frame(
    n = factor(n),
    Metodo = "Paramétrico (ajuste ruim)",
    EP_Estimado = res$EP_P,
    EP_Verdadeiro = ep_real
  )
  
  dados_plot <- rbind(dados_plot, df_np, df_p)
}

ggplot(dados_plot, aes(x = EP_Estimado, fill = Metodo)) +
  geom_density(alpha = 0.6) +
  facet_wrap(~ n, scales = "free_x", labeller = label_both) +
  geom_vline(aes(xintercept = EP_Verdadeiro),
             linetype = "dashed", color = "black") +
  scale_fill_manual(values = c(
    "Não-Paramétrico" = "blue",
    "Paramétrico (ajuste ruim)" = "red"
  )) +
  labs(
    title = "Comparação dos Estimadores de Erro Padrão por Bootstrap",
    subtitle = "Linha tracejada: erro padrão real",
    x = "EP Estimado",
    y = "Densidade"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")
```

O bootstrap não paramétrico apresenta um erro padrão muito próximo do EP verdadeiro em todos os tamanhos amostrais. Ao reamostrar diretamente dos dados, não faz suposições sobre a distribuição (além de i.i.d.) e por isso reflete de forma fiel a variabilidade dos dados amostrais. Já o bootstrap paramétrico subestima o erro padrão em todos os tamanhos amostrais, consequência da má especificação; mesmo com $n$ grande, o método paramétrico mas incorreto leva a uma inferência equivocada.

# Questão 06

Faça uma adaptação da função apresentada no Exemplo 4.11 (apostila em HTML) de tal forma que exista um argumento para definir o tipo de teste (bilateral, unilateral à esquerda ou unilateral à direita). Use um estudo Monte Carlo para estimar a **função poder** em um teste unilateral à esquerda, considerando diferentes tamanhos amostrais e gerando dados da distribuição Exponencial. Utilize o mesmo tamanho amostral para as duas amostras das populações comparadas, fixe o valor esperado da primeira população e altere o valor esperado da segunda população.

# Questão 07

Realize um estudo de Monte Carlo para estimar a função poder do teste de hipóteses bootstrap para a média de uma população e compare com a função poder estimada para o teste $t$ em uma situação em que uma hipótese do teste é violada.

## Solução

### Passo a passo

1. Defina os parâmetros da simulação.

2. Implemente a função do teste bootstrap para a média: centralize a amostra sob $H0$, reamostre $B$ vezes da amostra centrada, calcular a estatística $t^*$ em cada réplica, e calcule o p-valor no bootstrap como proporção de $|t^*| >= |t_{obs}|$. A 

3. Implemente a rotina de Monte Carlo e, para cada $mu$ em uma grade, repita $M$ vezes: gere uma amostra da população (nesse caso, a escolhida que viola a hipótese de normalidade do teste foi $\chi^2$ com graus de liberdade = $mu$), aplique o teste $t$ clássico e o teste bootstrap. Conte as rejeições e estime poder pela proporção.

4. Execute a simulação e avalie a eficiência.

Nesse cenário, as hipóteses são:

$$
\begin{cases}
H_0: \mu = 2 \\
H_1: \mu \neq 2
\end{cases}
$$

### Implementação do código

```{r}

```

CORRIGIR!

O teste $t$ padrão apresentou um poder de $0.0574$, o que é ligeiramente superior ao nível nominal $\alpha=0.05$. Isso indica que, devido à forte assimetria da distribuição Qui-quadrado e ao tamanho amostral limitado ($n=30$), o teste $t$ tem uma taxa de rejeição inflacionada.

O Teste Bootstrap estimou o poder em $0.0510$ quando $\mu_{real} = 2$. Este valor está muito mais próximo do nível nominal $\alpha=0.05$. Isso demonstra a robustez do método Bootstrap Não Paramétrico para testes de hipóteses, pois ele se baseia na distribuição empírica (que já captura a assimetria), não dependendo da suposição de normalidade populacional.

Para os valores sob a hipótese alternativa ($\mu \neq 2$), ambos os testes apresentaram poder semelhante. Contudo, dado que o Teste $t$ tem um nível empírico inflacionado em $H_0$, a sua estimativa de poder em $H_1$ é menos confiável em termos de manter o controle do erro Tipo I. O Teste Bootstrap forneceu uma função poder comparável, mantendo simultaneamente um nível empírico mais próximo do alvo nominal, o que o torna o método preferível neste cenário de violação de suposição.