---
title: "Lista 04 de MCCD II"
author: "Emanuelle, Maria Luiza e Mariana Fleming"
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(knitr)
```

# Questão 01

Gere amostras de tamanho $n = 10$ e $50$, e estime erro padrão e viés da média amostral como estimador da média populacional nas seguintes situações:  

a) $X \sim N(0, \sigma^2)$  
b) $X \sim \text{Gama}(2, 5)$  
c) Outra distribuição de sua escolha.  

Compare com o valor teórico nas três situações.

```{r se-bias}
M <- 10000  
size <- c(10, 50)

metrics <- function(n, dist_func, true_mean, true_sd, dist_name) {
  sample_means <- replicate(M, mean(dist_func(n)))
  
  est_bias <- mean(sample_means) - true_mean
  est_se <- sd(sample_means)
  
  
  the_bias <- 0
  the_se <- true_sd / sqrt(n)
  
  return(data.frame(
    Distribuicao = dist_name,
    n = n,
    Vies_Estimado = round(est_bias, 5),
    Vies_Teorico = the_bias,
    SE_Estimado = round(est_se, 5),
    SE_Teorico = round(the_se, 5)
  ))
}
```

a) $X \sim N(0, \sigma^2)$  

```{r se-bias-a}
sigma <- 1
mu <- 0

distribution <- function(n) rnorm(n, mean = mu, sd = sigma)

rn_10 <- metrics(10, distribution, mu, sigma, "Normal(0,1)")
rn_50 <- metrics(50, distribution, mu, sigma, "Normal(0,1)")

tabela <- data.frame(
  Distribuicao = c(rn_10$Distribuicao, rn_50$Distribuicao),
  Tamanho = c(rn_10$n, rn_50$n),
  Vies.Teorico = c(rn_10$Vies_Teorico, rn_50$Vies_Teorico),
  Vies.Estimado = c(rn_10$Vies_Estimado, rn_50$Vies_Estimado),
  SE.Teorico = c(rn_10$SE_Teorico, rn_50$SE_Teorico),
  SE.Estimado = c(rn_10$SE_Estimado, rn_50$SE_Estimado)
)

kable(tabela)
```

b) $X \sim \text{Gama}(2, 5)$  

```{r se-bias-b}
a <- 2
b <- 5
mu <- a / b
sigma <- sqrt(a / (b^2))

distribution <- function(n) rgamma(n, shape = a, rate = b)

rn_10 <- metrics(10, distribution, mu, sigma, "Gama(2,5)")
rn_50 <- metrics(50, distribution, mu, sigma, "Gama(2,5)")

tabela <- data.frame(
  Distribuicao = c(rn_10$Distribuicao, rn_50$Distribuicao),
  Tamanho = c(rn_10$n, rn_50$n),
  Vies.Teorico = c(rn_10$Vies_Teorico, rn_50$Vies_Teorico),
  Vies.Estimado = c(rn_10$Vies_Estimado, rn_50$Vies_Estimado),
  SE.Teorico = c(rn_10$SE_Teorico, rn_50$SE_Teorico),
  SE.Estimado = c(rn_10$SE_Estimado, rn_50$SE_Estimado)
)

kable(tabela)
```

c) $X \sim \text{Beta}(2, 2)$

```{r se-bias-b}
alpha <- 2
beta <- 2

mu <- alpha / (alpha + beta)
var <- (alpha * beta) / ((alpha + beta)^2 * (alpha + beta + 1))
sigma <- sqrt(var)

distribution <- function(n) rbeta(n, shape1 = alpha, shape2 = beta)

rn_10 <- metrics(10, distribution, mu, sigma, "Beta(2,2)")
rn_50 <- metrics(50, distribution, mu, sigma, "Beta(2,2)")

tabela <- data.frame(
  Distribuicao = c(rn_10$Distribuicao, rn_50$Distribuicao),
  Tamanho = c(rn_10$n, rn_50$n),
  Vies.Teorico = c(rn_10$Vies_Teorico, rn_50$Vies_Teorico),
  Vies.Estimado = c(rn_10$Vies_Estimado, rn_50$Vies_Estimado),
  SE.Teorico = c(rn_10$SE_Teorico, rn_50$SE_Teorico),
  SE.Estimado = c(rn_10$SE_Estimado, rn_50$SE_Estimado)
)

kable(tabela)
```

# Questão 02

Considere os seguintes estimadores para variância populacional:

$\hat{\sigma}^2_1 = \dfrac{1}{n - 1}\sum_{i=1}^n (x_i - \bar{x})^2$  
$\hat{\sigma}^2_2 = \dfrac{1}{n}\sum_{i=1}^n (x_i - \bar{x})^2$

Gere amostras de tamanho $n = 30$ e estime erro padrão e viés com estes estimadores da variância populacional nas seguintes situações:  

a) $X \sim N(0, \sigma^2)$  
b) $X \sim \text{Gama}(2, 5)$  
c) Outra distribuição de sua escolha.

```{r var-comp}
set.seed(123)
R <- 10000   
n <- 30

comp_vars <- function(r_func, true_var, dist_name) {
  samples <- matrix(r_func(n * R), ncol = R)
 
  est1_val <- apply(samples, 2, var)
  est2_val <- est1_val * (n - 1) / n
 
  bias1 <- mean(est1_val) - true_var
  se1 <- sd(est1_val)
  
  bias2 <- mean(est2_val) - true_var
  se2 <- sd(est2_val)
  
  return(data.frame(
    Distribuicao = dist_name,
    Verdadeira_Var = true_var,
    Est1_Vies = round(bias1, 5),
    Est1_SE = round(se1, 5),
    Est2_Vies = round(bias2, 5),
    Est2_SE = round(se2, 5)
  ))
}

kable(tabela)

```

a) $X \sim N(0, \sigma^2)$  

```{r var-comp-a}
normal <- comp_vars(
  function(x) rnorm(x, mean=0, sd=1), 
  true_var = 1, 
  dist_name = "Normal(0,1)"
)

tabela <- data.frame(
  Distribuicao = normal$Distribuicao,
  Var.verdadeira = normal$Verdadeira_Var,
  Vies.Est1 = normal$Est1_Vies,
  SE.Est1 = normal$Est1_SE,
  Vies.Est2 = normal$Est2_Vies,
  SE.Est2 = normal$Est2_SE
)

kable(tabela)

```

b) $X \sim \text{Gama}(2, 5)$  

```{r var-comp-b}
gama <- comp_vars(
  function(x) rgamma(x, shape=2, rate=5), 
  true_var = 0.08, 
  dist_name = "Gama(2,5)"
)

tabela <- data.frame(
  Distribuicao = gama$Distribuicao,
  Var.verdadeira = gama$Verdadeira_Var,
  Vies.Est1 = gama$Est1_Vies,
  SE.Est1 = gama$Est1_SE,
  Vies.Est2 = gama$Est2_Vies,
  SE.Est2 = gama$Est2_SE
)

kable(tabela)

```

c) $X \sim \text{Beta}(2, 2)$c) $X \sim \text{Beta}(2, 2)$

```{r var-comp-c}
beta <- comp_vars(
  function(x) rbeta(x, shape1=2, shape2=2), 
  true_var = 0.05, 
  dist_name = "Beta(2,2)"
)

tabela <- data.frame(
  Distribuicao = beta$Distribuicao,
  Var.verdadeira = beta$Verdadeira_Var,
  Vies.Est1 = beta$Est1_Vies,
  SE.Est1 = beta$Est1_SE,
  Vies.Est2 = beta$Est2_Vies,
  SE.Est2 = beta$Est2_SE
)
```

# Questão 03

Implemente funções para calcular os intervalos de confiança bootstrap studentizado e BCa. Compare o resultado fornecido com o intervalo construído com as funções do pacote `boot`.

## Solução

**IC Bootstrap Studentizado**

O intervalo de confiança Bootstrap Studentizado é baseado na distribuição amostral de uma estatística studentizada gerada por reamostragem. O intervalo de $100(1 - \alpha)\%$ de confiança é dado por:

$$ \left[ \hat{\theta} - t^*_{1-\alpha/2} \hat{se}(\hat{\theta}); \hat{\theta} - t^*_{\alpha/2} \hat{se}(\hat{\theta}) \right] $$

### Passo a passo

1. Calcule $\hat{\theta}$.

2. Para cada réplica $b = 1, \dots, B$, gere uma amostra $x^{*(b)}$ por amostragem com reposição da amostra observada, calcule $\hat{\theta}^{(b)}$ e a estatística studentizada:

$$
t^{(b)} = \frac{\hat{\theta}^{(b)} - \hat{\theta}}{\hat{se}(\hat{\theta}^{(b)})}
$$

3. Calcule os quantis $t^*_{\alpha/2}$ e $t^*_{1-\alpha/2}$ a partir da amostra ordenada de $t^{(b)}$ e construa o intervalo de confiança.

### Implementação do código

```{r ex3-student}
ic_bootstrap_studentizado <- function(x, stat = mean, B = 1000, R = 200, alpha = 0.05) {
  n <- length(x)
  theta_chapeu <- stat(x)
  ep_chapeu <- sd(replicate(R, stat(sample(x, n, replace = TRUE))))
  
  t_boot <- numeric(B)
  for (b in 1:B) {
    x_estrela <- sample(x, n, replace = TRUE)
    theta_b <- stat(x_estrela)
    ep_b <- sd(replicate(R, stat(sample(x_estrela, n, replace = TRUE))))
    t_boot[b] <- (theta_b - theta_chapeu) / ep_b
  }
  
  t_quant <- quantile(t_boot, c(alpha / 2, 1 - alpha / 2))
  ic <- c(theta_chapeu - t_quant[2] * ep_chapeu,
          theta_chapeu - t_quant[1] * ep_chapeu)
  return(ic)
}
```

**IC Bootstrap BCa**

O intervalo de confiança BCa (Bias-Corrected and Accelerated) é uma versão modificada do intervalo percentílico que possui melhores propriedades teóricas e melhor desempenho. O intervalo BCa ajusta os quantis usuais por dois fatores: $\hat{z}_0$ (correção para viés) e $\hat{a}$ (aceleração/assimetria).

O intervalo de $100(1 - \alpha)\%$ de confiança BCa é dado pelos quantis empíricos $\hat{\theta}_{\alpha_1}$ e $\hat{\theta}_{\alpha_2}$ das réplicas bootstrap, onde $\alpha_1$ e $\alpha_2$ são os quantis ajustados:

$$
\alpha_1 = \Phi \left( \frac{\hat{z}_0 + \hat{z}_0 + z_{\alpha/2}}{1 - \hat{a}(\hat{z}_0 + z_{\alpha/2})} \right)
$$

$$
\alpha_2 = \Phi \left( \frac{\hat{z}_0 + \hat{z}_0 + z_{1-\alpha/2}}{1 - \hat{a}(\hat{z}_0 + z_{1-\alpha/2})} \right)
$$

onde $z_{\alpha} = \Phi^{-1}(\alpha)$ é o quantil da distribuição normal padrão.

### Passo a passo

1. Calcule $\hat{\theta}$.

2. Gere $B$ réplicas bootstrap $\hat{\theta}^{(b)}$.

3. Gere $n$ réplicas Jackknife $\hat{\theta}_{[-i]}$.

4. Calcule o fator de viés corrigido: $ \hat{z}_0 = \Phi^{-1} \left( \frac{1}{B} \sum_{b=1}^B I\{\hat{\theta}^{(b)} < \hat{\theta}\} \right) $.

5. Calcule o ajuste de assimetria utilizando as réplicas Jackknife:

$$
\hat{a} = \frac{\sum_{i=1}^n (\bar{\theta}_{[\cdot]} - \hat{\theta}_{[-i]})^3}{6(\sum_{i=1}^n (\bar{\theta}_{[\cdot]} - \hat{\theta}_{[-i]})^2)^{3/2}}
$$

onde $\bar{\theta}_{[\cdot]} = \frac{1}{n} \sum_{i=1}^n \hat{\theta}_{[-i]}$.

6. Calcule $\alpha_1$, $\alpha_2$ e os quantis empíricos $\hat{\theta}_{\alpha_1}$ e $\hat{\theta}_{\alpha_2}$ a partir da distribuição ordenada de $\hat{\theta}^{(b)}$.

### Implementação do código

```{r ex3-bca}
ic_bootstrap_bca <- function(x, stat = mean, B = 1000, alpha = 0.05) {
  n <- length(x)
  theta_chapeu <- stat(x)
  
  # bootstrap
  thetas <- replicate(B, stat(sample(x, n, replace = TRUE)))
  
  # jackknife
  jack <- sapply(1:n, function(i) stat(x[-i]))
  theta_barra <- mean(jack)
  
  # parâmetros BCa
  z0 <- qnorm(mean(thetas < theta_chapeu))
  a <- sum((theta_barra - jack)^3) / (6 * (sum((theta_barra - jack)^2))^(3/2))

  z_alfa <- qnorm(c(alpha / 2, 1 - alpha / 2))
  alfa <- pnorm(z0 + (z0 + z_alfa) / (1 - a * (z0 + z_alfa)))
  
  ic <- quantile(thetas, probs = alfa)
  
  return(ic)
}
```

**Comparação com o Pacote `boot`**

### Implementação do código

```{r ex3-boot}
library(boot)
set.seed(123456789)
x <- rnorm(30, mean = 5, sd = 2)

# necessário para "stud"

metricas_boot_student <- function(data, idx) {
  d <- data[idx]
  m <- mean(d)
  se <- sd(d) / sqrt(length(d))
  return(c(mean = m, se = se))
}

# retorna média e erro padrão
boot_obj <- boot(x, statistic = metricas_boot_student, R = 1000, sim = "ordinary", stype = "i")


ic_student <- ic_bootstrap_studentizado(x, stat = mean, B = 500, R = 100)
ic_bca <- ic_bootstrap_bca(x, stat = mean, B = 1000)

# funções do pacote
boot_student <- boot.ci(boot_obj, type = "stud")
boot_bca <- boot.ci(boot_obj, type = "bca")

resultado <- data.frame(
  Metodo = c("Studentizado (manual)",
             "Studentizado (pacote)",
             "BCa (manual)",
             "BCa (pacote)"),
  IC_Inferior = c(
    round(ic_student[1], 4),
    round(as.numeric(boot_student$student[,4]), 4),
    round(ic_bca[1], 4),
    round(boot_bca$bca[,4], 4)
  ),
  IC_Superior = c(
    round(ic_student[2], 4),
    round(as.numeric(boot_student$student[,5]), 4),
    round(ic_bca[2], 4),
    round(boot_bca$bca[,5], 4)
  )
)

kable(resultado)
```

Os resultados ficaram próximos, o que confirma que o código está performando bem.

# Questão 04

Faça um estudo de Monte Carlo para comparar a probabilidade de cobertura dos intervalos de confiança bootstrap para a média populacional gerando amostras das distribuições Normal e Lognormal. Para as duas distribuições, utilize tamanhos amostrais iguais a 20, 50 e 150. Considere 4 métodos bootstrap de sua escolha para a obtenção dos intervalos de confiança e também compare com a probabilidade de cobertura do intervalo paramétrico com a $t$-Student.

## Solução

### Passo a passo

Para cada distribuição (Normal, Lognormal)  
e para cada tamanho amostral (n = 20, 50, 150):

1. Repetimos o experimento de Monte Carlo:

   - Gerar uma amostra `x` da distribuição especificada.  
   - Calcular a média amostral $\hat{\theta}$ = mean(x).  
   - Gerar amostras bootstrap e obter:  
        * médias bootstrap `mean(x*)`  
        * erros padrão bootstrap `sd(x*)/sqrt(n)` (para o método studentized).  
   - Construir os seguintes intervalos de confiança:  
   
        * **IC t-Student paramétrico:** Usa a fórmula clássica baseada na normalidade e no erro-padrão amostral.  
        
        * **IC bootstrap percentile:** Usa diretamente os percentis da distribuição bootstrap das estatísticas. É simples, mas tende a falhar quando há viés ou forte assimetria  
        
        * **IC bootstrap basic:** Reflete o intervalo percentil em torno da estimativa observada. Corrige parcialmente o viés, mas ainda é instável.  
        
        * **IC bootstrap-t (studentized):** Padroniza a estatística usando o erro-padrão estimado em cada reamostragem. É mais estável e robusto  
        
        * **IC BCa: (Bias-Corrected and Accelerated)** Ajusta os limites percentis para corrigir viés e assimetria usando aceleração via jackknife. Funciona muito bem em cenários não simétricos
        
   - Verificar se cada IC contém a média populacional verdadeira.
   
2. Após todas as simulações, calculamos a **probabilidade de cobertura**  
   como a proporção de simulações em que o IC incluiu a média real.
   
   
```{r q4}
set.seed(2025)

# Número de simulações e de bootstraps
n_sim <- 500
B <- 500
alpha <- 0.05

# Intervalo BCa para a média

ic_bca <- function(x, media_amostra, medias_boot, alpha = 0.05) {
  # Viés do bootstrap
  prop_menor <- mean(medias_boot < media_amostra)
  prop_menor <- min(max(prop_menor, 1e-10), 1 - 1e-10)
  z0 <- qnorm(prop_menor)

  # Acelerador via jackknife
  n <- length(x)
  jack_means <- sapply(1:n, function(i) mean(x[-i]))
  media_jack <- mean(jack_means)
  num <- sum((media_jack - jack_means)^3)
  den <- 6 * (sum((media_jack - jack_means)^2)^(3/2))
  a <- ifelse(den == 0, 0, num / den)

  # Ajustes dos limites
  z_inf <- qnorm(alpha/2)
  z_sup <- qnorm(1 - alpha/2)

  p_inf <- pnorm(z0 + (z0 + z_inf) / (1 - a * (z0 + z_inf)))
  p_sup <- pnorm(z0 + (z0 + z_sup) / (1 - a * (z0 + z_sup)))

  # proteger para casos numéricos extremos
  p_inf <- min(max(p_inf, 0), 1)
  p_sup <- min(max(p_sup, 0), 1)

  c(
    quantile(medias_boot, p_inf, names = FALSE, type = 6),
    quantile(medias_boot, p_sup, names = FALSE, type = 6)
  )
}

# Calcula todos os intervalos de confiança

calcular_ics <- function(x, B = 1000, alpha = 0.05) {
  n <- length(x)
  media_obs <- mean(x)
  erro_padrao_obs <- sd(x) / sqrt(n)

  # evita sd = 0 
  if (!is.finite(erro_padrao_obs) || erro_padrao_obs == 0) {
    erro_padrao_obs <- NA_real_
  }

  # Bootstrap da média e do erro padrão
  medias_boot <- numeric(B)
  erros_padrao_boot <- numeric(B)

  for (b in 1:B) {
    amostra_b <- sample(x, n, replace = TRUE)
    medias_boot[b] <- mean(amostra_b)

    sd_b <- sd(amostra_b)
    erros_padrao_boot[b] <- ifelse(sd_b == 0, NA_real_, sd_b / sqrt(n))
  }

  # IC t paramétrico
  ic_t <- if (!is.na(erro_padrao_obs)) {
    media_obs + qt(1 - alpha/2, df = n - 1) * c(-1, 1) * erro_padrao_obs
  } else c(NA, NA)

  # IC percentile
  ic_percentil <- quantile(medias_boot, c(alpha/2, 1 - alpha/2), type = 6, na.rm = TRUE)

  # IC basic
  ic_basic <- 2 * media_obs - rev(ic_percentil)

  # IC studentized (bootstrap-t)
  t_star <- (medias_boot - media_obs) / erros_padrao_boot
  t_star <- t_star[is.finite(t_star)]

  ic_t_star <- if (length(t_star) > 10 && !is.na(erro_padrao_obs)) {
    q <- quantile(t_star,
                  c(1 - alpha/2, alpha/2),
                  type = 6, na.rm = TRUE)
    sort(media_obs - q * erro_padrao_obs)
  } else c(NA, NA)

  # IC BCa
  ic_bca_val <- tryCatch(
    ic_bca(x, media_obs, medias_boot, alpha),
    error = function(e) c(NA, NA)
  )

  list(
    t = ic_t,
    percentil = ic_percentil,
    basic = ic_basic,
    t_estrela = ic_t_star,
    bca = ic_bca_val
  )
}

# Roda uma configuração (dist × n)

rodar_simulacao <- function(distribuicao, n, n_sim, B, alpha, parametros) {
  # Função geradora e média verdadeira
  if (distribuicao == "normal") {
    gerar <- function(n) rnorm(n, parametros$media, parametros$sd)
    media_verdadeira <- parametros$media
  } else {
    gerar <- function(n) rlnorm(n, parametros$media_log, parametros$sd_log)
    media_verdadeira <- exp(parametros$media_log + parametros$sd_log^2 / 2)
  }

  cobertura <- matrix(FALSE, n_sim, 5)
  colnames(cobertura) <- c("t", "percentil", "basic", "t_estrela", "bca")

  # simulações
  for (i in 1:n_sim) {
    x <- gerar(n)
    ics <- calcular_ics(x, B, alpha)

    for (nome_ic in names(ics)) {
      intervalo <- ics[[nome_ic]]

      if (any(is.na(intervalo))) {
        cobertura[i, nome_ic] <- NA
      } else {
        cobertura[i, nome_ic] <-
          media_verdadeira >= intervalo[1] &&
          media_verdadeira <= intervalo[2]
      }
    }
  }

  colMeans(cobertura, na.rm = TRUE)
}

# Tamanhos amostrais e distribuições

ns <- c(20, 50, 150)
distrs <- c("normal", "lognormal")

param_normal <- list(media = 0, sd = 1, media_log = NA, sd_log = NA)
param_lognorm <- list(media = NA, sd = NA, media_log = 0, sd_log = 1)

resultados <- list()

for (dist in distrs) {
  for (n in ns) {
    params <- if (dist == "normal") param_normal else param_lognorm
    resultados[[paste(dist, n, sep = "_")]] <-
      rodar_simulacao(dist, n, n_sim, B, alpha, params)
  }
}

final <- do.call(rbind, resultados)
kable(round(final, 4), caption = "Probabilidade de cobertura dos intervalos de confiança (Bootstrap × t-paramétrico)")

```


Os resultados indicam que, na distribuição **normal**, todos os métodos alcançam coberturas próximas ao esperado, mesmo para amostras pequenas, e a estabilidade aumenta com o tamanho da amostra. 

Já na **lognormal**, especialmente com n = 20, a cobertura cai de forma mais evidente, porque a assimetria afeta métodos como **percentil** e **basic**. Com amostras maiores, o desempenho melhora, mas ainda permanece abaixo do cenário normal. Entre os métodos avaliados, **BCa** e **t-bootstrap** apresentam desempenho mais consistente nos casos com assimetria ou tamanhos amostrais menores.

# Questão 05

Compare os bootstraps paramétrico e não paramétrico na estimação do erro padrão de $\bar{X}$ para estimar $E[X]$ quando os dados são gerados da distribuição binomial negativa. No bootstrap paramétrico, assuma que os dados são oriundos da distribuição Poisson para avaliar o efeito da má especificação da distribuição populacional. Utilize 3 valores diferentes para tamanho amostral.

## Solução

O bootstrap não paramétrico estima a distribuição amostral reamostrando a partir da distribuição empírica (com reposição). Já o bootstrap paramétrico assume uma forma paramétrica e simula a partir dessa distribuição estimada.

### Passo a passo

1. Defina os parâmetros da simulação: a distribuição verdadeira (no caso, Binomial Negativa com $r=4$, $p=0.75$) e seus parâmetros, incluindo a variância e o erro padrão verdadeiro. Serão considerados três tamanhos amostrais: $n = 30, 100, 500$.

2. Para cada tamanho amostral e para cada uma das $M = 1000$ iterações, gere uma amostra da Binomial Negativa, calcule o erro padrão via bootstrap não paramétrico, reamostrando a própria amostra, além do erro padrão via bootstrap paramétrico assumindo incorretamente uma outra distribuição (no caso, Poisson).

3. Para cada $n$, guarde os erros padrão verdadeiros, e os estimados pelos métodos BNP e BP e compare.

### Implementação do código

```{r ex5}
M <- 1000
B <- 2000
tamanhos <- c(30, 100, 500) 

r <- 4 
p <- 0.75 

var_x <- r * (1 - p) / (p^2) 

# calcula o erro padrão verdadeiro de X barra
calcula_ep <- function(n) {
  sqrt(var_x / n)
}

ep <- list()

simulacao <- function(tamanho_amostral, M, B, r, p) {
  
  ep_np <- numeric(M) # não paramétrico
  ep_p <- numeric(M) # paramétrico
  
  ep_verdadeiro <- calcula_ep(tamanho_amostral)

  for (i in 1:M) {
    # geração da amostra real
    amostra <- rnbinom(tamanho_amostral, size = r, prob = p)
    
    # não paramétrico
    media_np <- replicate(B, {
      mean(sample(amostra, tamanho_amostral, replace = TRUE))
    })
    ep_np[i] <- sd(media_np)
    
    # paramétrico (mal especificado)
    lambda_chapeu <- mean(amostra)
    
    media_p <- replicate(B, {
      mean(rpois(tamanho_amostral, lambda = lambda_chapeu))
    })
    ep_p[i] <- sd(media_p)
  }
  
  return(data.frame(
    n = tamanho_amostral,
    EP_Verdadeiro = ep_verdadeiro,
    EP_NP = ep_np,
    EP_P = ep_p
  ))
  
}

set.seed(123456789)
for (n in tamanhos) {
  ep[[as.character(n)]] <- simulacao(n, M, B, r, p)
}


dados_plot <- data.frame()
for (n_str in names(ep)) {
  res <- ep[[n_str]]
  n <- res$n[1]  # apenas o valor de n (é constante dentro de cada data.frame)
  ep_real <- res$EP_Verdadeiro[1]
  
  df_np <- data.frame(
    n = factor(n),
    Metodo = "Não-Paramétrico",
    EP_Estimado = res$EP_NP,
    EP_Verdadeiro = ep_real
  )
  
  df_p <- data.frame(
    n = factor(n),
    Metodo = "Paramétrico (ajuste ruim)",
    EP_Estimado = res$EP_P,
    EP_Verdadeiro = ep_real
  )
  
  dados_plot <- rbind(dados_plot, df_np, df_p)
}

ggplot(dados_plot, aes(x = EP_Estimado, fill = Metodo)) +
  geom_density(alpha = 0.6) +
  facet_wrap(~ n, scales = "free_x", labeller = label_both) +
  geom_vline(aes(xintercept = EP_Verdadeiro),
             linetype = "dashed", color = "black") +
  scale_fill_manual(values = c(
    "Não-Paramétrico" = "blue",
    "Paramétrico (ajuste ruim)" = "red"
  )) +
  labs(
    title = "Comparação dos Estimadores de Erro Padrão por Bootstrap",
    subtitle = "Linha tracejada: erro padrão real",
    x = "EP Estimado",
    y = "Densidade"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")
```

O bootstrap não paramétrico apresenta um erro padrão muito próximo do EP verdadeiro em todos os tamanhos amostrais. Ao reamostrar diretamente dos dados, não faz suposições sobre a distribuição (além de i.i.d.) e por isso reflete de forma fiel a variabilidade dos dados amostrais. Já o bootstrap paramétrico subestima o erro padrão em todos os tamanhos amostrais, consequência da má especificação; mesmo com $n$ grande, o método paramétrico mas incorreto leva a uma inferência equivocada.

# Questão 06

Faça uma adaptação da função apresentada no Exemplo 4.11 (apostila em HTML) de tal forma que exista um argumento para definir o tipo de teste (bilateral, unilateral à esquerda ou unilateral à direita). Use um estudo Monte Carlo para estimar a **função poder** em um teste unilateral à esquerda, considerando diferentes tamanhos amostrais e gerando dados da distribuição Exponencial. Utilize o mesmo tamanho amostral para as duas amostras das populações comparadas, fixe o valor esperado da primeira população e altere o valor esperado da segunda população.

## Solução

Função de teste bootstrap adaptada para três tipos de hipóteses:

```{r q6_1}
teste_boot <- function(x, y, B = 500, tipo = "bilateral"){
  t_obs <- t.test(x, y, var.equal = F)$statistic
  
  z <- c(x, y)
  n <- length(x)
  t_boot <- numeric(B)
  
  for(b in 1:B){
    amostra <- sample(z, replace = T)
    x_b <- amostra[1:n]
    y_b <- amostra[-(1:n)]
    t_boot[b] <- t.test(x_b, y_b, var.equal = F)$statistic
  }
  
  # Cálculo do p-valor conforme o tipo de teste desejado
  if(tipo == "bilateral"){
    p_valor <- mean(abs(t_boot) >= abs(t_obs))
  } else if(tipo == "esquerda"){
    p_valor <- mean(t_boot <= t_obs)
  } else if(tipo == "direita"){
    p_valor <- mean(t_boot >= t_obs)
  }
  
  return(p_valor)
}

```


Estudo Monte Carlo: Estimativa da Função Poder
```{r q6_3}
# Parâmetros para o estudo de simulação

ns <- c(20, 50)                # tamanhos de amostra 
mu1 <- 5                       # média da primeira distribuição exponencial
mu2_vals <- c(5, 6, 7, 8)      # valores de média para a segunda distribuição
M <- 500                       # n de simulações
B <- 500                       # n de réplicas bootstraps

# Tabela para armazenar as proporções de rejeição
resultados <- matrix(NA, nrow = length(ns), ncol = length(mu2_vals))
rownames(resultados) <- paste0("n=", ns)
colnames(resultados) <- paste0("mu2=", mu2_vals)

# varre tamanhos de amostra e valores de mu2
for(i in 1:length(ns)){
  n <- ns[i]
  
  for(j in 1:length(mu2_vals)){
    mu2 <- mu2_vals[j]
    rejeicoes <- 0            # contador de rejeições da H0
    
    for(k in 1:M){
      # Gera duas amostras exponenciais independentes
      x <- rexp(n, rate = 1/mu1)
      y <- rexp(n, rate = 1/mu2)
      
      # Calcula p-valor via bootstrap adaptado para teste unilateral à esquerda
      p_val <- teste_boot(x, y, B, tipo = "esquerda")
      
      if(p_val <= 0.05){
        rejeicoes <- rejeicoes + 1
      }
    }
    
    # Proporção de vezes em que H0 foi rejeitada
    resultados[i, j] <- rejeicoes / M
    }
}


df_poder <- as.data.frame(resultados) %>%
  mutate(n = rownames(resultados)) %>%
  pivot_longer(cols = starts_with("mu2"), 
               names_to = "mu2", 
               values_to = "poder")

df_poder$mu2 <- as.numeric(gsub("mu2=", "", df_poder$mu2))
df_poder$n <- as.numeric(gsub("n=", "", df_poder$n))
```


```{r q6_4, echo = FALSE}

kable(resultados, digits = 3,
      caption = "Estimativa da função poder para diferentes tamanhos amostrais",
      longtable = FALSE, 
      booktabs = TRUE)
```

Os resultados mostram que o poder do teste aumenta conforme a média da segunda população fica maior que a da primeira. Isso ocorre porque o teste é unilateral à esquerda $(\mu_1 < \mu_2)$, ou seja, quanto mais a segunda média cresce em relação à primeira, mais evidente fica a evidência a favor da hipótese alternativa. 

Observa-se também que, com amostras maiores $(n=50)$, o teste detecta essa diferença com muito mais facilidade, fazendo a curva de poder subir rapidamente. Já com amostras pequenas $(n=20)$, o aumento do poder é mais lento devido à maior variabilidade amostral."

# Questão 07

Realize um estudo de Monte Carlo para estimar a função poder do teste de hipóteses bootstrap para a média de uma população e compare com a função poder estimada para o teste $t$ em uma situação em que uma hipótese do teste é violada.

## Solução

### Passo a passo

1. Defina os parâmetros da simulação.

2. Implemente a função do teste bootstrap para a média: centralize a amostra sob $H0$, reamostre $B$ vezes da amostra centrada, calcular a estatística $t^*$ em cada réplica, e calcule o p-valor no bootstrap como proporção de $|t^*| >= |t_{obs}|$. A 

3. Implemente a rotina de Monte Carlo e, para cada $mu$ em uma grade, repita $M$ vezes: gere uma amostra da população (nesse caso, a escolhida que viola a hipótese de normalidade do teste foi $\chi^2$ com graus de liberdade = $mu$), aplique o teste $t$ clássico e o teste bootstrap. Conte as rejeições e estime poder pela proporção.

4. Execute a simulação e avalie a eficiência.

Nesse cenário, as hipóteses são:

$$
\begin{cases}
H_0: \mu = 2 \\
H_1: \mu \neq 2
\end{cases}
$$

### Implementação do código

```{r ex7}
teste_boot <- function(z, mu0, B = 1000) {
  n <- length(z)

  teste_t_obs <- t.test(z, mu = mu0)
  t_obs <- teste_t_obs$statistic
  
  # translação para ter média mu0.
  z_til <- z - mean(z) + mu0
  
  t_estrela <- numeric(B)
  
  for(b in 1:B){
    # amostra centrada em mu0
    z_estrela <- sample(z_til, size = n, replace = TRUE)
    t_estrela[b] <- t.test(z_estrela, mu = mu0)$statistic
  }

  p_valor <- ( sum(t_estrela >= abs(t_obs)) + sum(t_estrela <= -abs(t_obs)) ) / B
  
  return(p_valor)
}

poder_mc <- function(mu_vec, n, M, B, alfa) {
  
  num_mu <- length(mu_vec)
  poder_t <- numeric(num_mu)
  poder_boot <- numeric(num_mu)
  mu0 <- 2
  
  for (i in 1:num_mu) {
    mu_real <- mu_vec[i]
    # Em uma distribuicao Chi-quadrado, E[X] = nu. Entao, nu = mu_real.
    nu_real <- mu_real 
    
    rejeicoes_t <- 0
    rejeicoes_boot <- 0
    
    # Monte Carlo
    for (m in 1:M) {
      dados_mc <- rchisq(n, df = nu_real)
      
      p_valor_t <- t.test(dados_mc, mu = mu0, alternative = "two.sided")
      if (p_valor_t$p.value <= alfa) {
        rejeicoes_t <- rejeicoes_t + 1
      }
      
      p_valor_boot <- teste_boot(dados_mc, mu0 = mu0, B = B)
      if (p_valor_boot <= alfa) {
        rejeicoes_boot <- rejeicoes_boot + 1
      }
    }
    
    poder_t[i] <- rejeicoes_t / M
    poder_boot[i] <- rejeicoes_boot / M
  }
  
  return(data.frame(
    mu_real = mu_vec,
    Poder_T = poder_t,
    Poder_Bootstrap = poder_boot
  ))
}

mu_valores <- c(1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0)
M <- 500
B <- 1000
alfa <- 0.05

set.seed(123456789)

resultados1 <- poder_mc(
  mu_vec = mu_valores,
  n = 30,
  M = M,
  B = B,
  alfa = alfa
)

kable(resultados1)

df_plot1 <- data.frame(
  mu_real = resultados1$mu_real,
  Poder = c(resultados1$Poder_T, resultados1$Poder_Bootstrap),
  Metodo = factor(rep(c("Teste T (Violado)", "Bootstrap"), each = length(mu_valores)))
)

resultados2 <- poder_mc(
  mu_vec = mu_valores,
  n = 100,
  M = M,
  B = B,
  alfa = alfa
)

kable(resultados2)

par(mfrow=c(1,2))

df_plot2 <- data.frame(
  mu_real = resultados2$mu_real,
  Poder = c(resultados2$Poder_T, resultados2$Poder_Bootstrap),
  Metodo = factor(rep(c("Teste T (Violado)", "Bootstrap"), each = length(mu_valores)))
)

ggplot(df_plot1, aes(x = mu_real, y = Poder, color = Metodo)) +
  geom_line(size = 1) +
  geom_point(size = 3) +
  geom_vline(xintercept = 2, linetype = "dashed", color = "black", alpha = 0.7) +
  geom_hline(yintercept = alfa, linetype = "dotted", color = "gray50") +
  scale_y_continuous(limits = c(0, 1)) +
  labs(
    title = "Poder: Teste T vs. Bootstrap (n = 30)",
    subtitle = "População Qui-quadrado",
    x = expression(paste(mu)),
    y = "Poder"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")

ggplot(df_plot2, aes(x = mu_real, y = Poder, color = Metodo)) +
  geom_line(size = 1) +
  geom_point(size = 3) +
  geom_vline(xintercept = 2, linetype = "dashed", color = "black", alpha = 0.7) +
  geom_hline(yintercept = alfa, linetype = "dotted", color = "gray50") +
  scale_y_continuous(limits = c(0, 1)) +
  labs(
    title = "Poder: Teste T vs. Bootstrap (n = 100)",
    subtitle = "População Qui-quadrado",
    x = expression(paste(mu)),
    y = "Poder"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")
```


O método não paramétrico usando bootstrap é melhor nesse caso, uma vez que não depende de hipóteses sobre a distribuição dos dados. A violação de suposição de normalidade tem um grave custo ao teste paramétrico $t$-Student.
