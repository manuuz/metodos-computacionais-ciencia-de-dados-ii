---
title: "Lista 04 de MCCD II"
author: "Emanuelle, Maria Luiza e Mariana Fleming"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(knitr)
```

# Questão 01

Gere amostras de tamanho $n = 10$ e $50$, e estime erro padrão e viés da média amostral como estimador da média populacional nas seguintes situações:  

a) $X \sim N(0, \sigma^2)$  
b) $X \sim \text{Gama}(2, 5)$  
c) Outra distribuição de sua escolha.  

Compare com o valor teórico nas três situações.

# Questão 02

Considere os seguintes estimadores para variância populacional:

$\hat{\sigma}^2_1 = \dfrac{1}{n - 1}\sum_{i=1}^n (x_i - \bar{x})^2$  
$\hat{\sigma}^2_2 = \dfrac{1}{n}\sum_{i=1}^n (x_i - \bar{x})^2$

Gere amostras de tamanho $n = 30$ e estime erro padrão e viés com estes estimadores da variância populacional nas seguintes situações:  

a) $X \sim N(0, \sigma^2)$  
b) $X \sim \text{Gama}(2, 5)$  
c) Outra distribuição de sua escolha.

# Questão 03

Implemente funções para calcular os intervalos de confiança bootstrap studentizado e BCa. Compare o resultado fornecido com o intervalo construído com as funções do pacote `boot`.

## Solução

**IC Bootstrap Studentizado**

O intervalo de confiança Bootstrap Studentizado é baseado na distribuição amostral de uma estatística studentizada gerada por reamostragem. O intervalo de $100(1 - \alpha)\%$ de confiança é dado por:

$$ \left[ \hat{\theta} - t^*_{1-\alpha/2} \hat{se}(\hat{\theta}); \hat{\theta} - t^*_{\alpha/2} \hat{se}(\hat{\theta}) \right] $$

### Passo a passo

1. Calcule $\hat{\theta}$.

2. Para cada réplica $b = 1, \dots, B$, gere uma amostra $x^{*(b)}$ por amostragem com reposição da amostra observada, calcule $\hat{\theta}^{(b)}$ e a estatística studentizada:

$$
t^{(b)} = \frac{\hat{\theta}^{(b)} - \hat{\theta}}{\hat{se}(\hat{\theta}^{(b)})}
$$

3. Calcule os quantis $t^*_{\alpha/2}$ e $t^*_{1-\alpha/2}$ a partir da amostra ordenada de $t^{(b)}$ e construa o intervalo de confiança.

### Implementação do código

```{r ex3-student}
ic_bootstrap_studentizado <- function(x, stat = mean, B = 1000, R = 200, alpha = 0.05) {
  n <- length(x)
  theta_chapeu <- stat(x)
  ep_chapeu <- sd(replicate(R, stat(sample(x, n, replace = TRUE))))
  
  t_boot <- numeric(B)
  for (b in 1:B) {
    x_estrela <- sample(x, n, replace = TRUE)
    theta_b <- stat(x_estrela)
    ep_b <- sd(replicate(R, stat(sample(x_estrela, n, replace = TRUE))))
    t_boot[b] <- (theta_b - theta_chapeu) / ep_b
  }
  
  t_quant <- quantile(t_boot, c(alpha / 2, 1 - alpha / 2))
  ic <- c(theta_chapeu - t_quant[2] * ep_chapeu,
          theta_chapeu - t_quant[1] * ep_chapeu)
  return(ic)
}
```

**IC Bootstrap BCa**

O intervalo de confiança BCa (Bias-Corrected and Accelerated) é uma versão modificada do intervalo percentílico que possui melhores propriedades teóricas e melhor desempenho. O intervalo BCa ajusta os quantis usuais por dois fatores: $\hat{z}_0$ (correção para viés) e $\hat{a}$ (aceleração/assimetria).

O intervalo de $100(1 - \alpha)\%$ de confiança BCa é dado pelos quantis empíricos $\hat{\theta}_{\alpha_1}$ e $\hat{\theta}_{\alpha_2}$ das réplicas bootstrap, onde $\alpha_1$ e $\alpha_2$ são os quantis ajustados:

$$
\alpha_1 = \Phi \left( \frac{\hat{z}_0 + \hat{z}_0 + z_{\alpha/2}}{1 - \hat{a}(\hat{z}_0 + z_{\alpha/2})} \right)
$$

$$
\alpha_2 = \Phi \left( \frac{\hat{z}_0 + \hat{z}_0 + z_{1-\alpha/2}}{1 - \hat{a}(\hat{z}_0 + z_{1-\alpha/2})} \right)
$$

onde $z_{\alpha} = \Phi^{-1}(\alpha)$ é o quantil da distribuição normal padrão.

### Passo a passo

1. Calcule $\hat{\theta}$.

2. Gere $B$ réplicas bootstrap $\hat{\theta}^{(b)}$.

3. Gere $n$ réplicas Jackknife $\hat{\theta}_{[-i]}$.

4. Calcule o fator de viés corrigido: $ \hat{z}_0 = \Phi^{-1} \left( \frac{1}{B} \sum_{b=1}^B I\{\hat{\theta}^{(b)} < \hat{\theta}\} \right) $.

5. Calcule o ajuste de assimetria utilizando as réplicas Jackknife:

$$
\hat{a} = \frac{\sum_{i=1}^n (\bar{\theta}_{[\cdot]} - \hat{\theta}_{[-i]})^3}{6(\sum_{i=1}^n (\bar{\theta}_{[\cdot]} - \hat{\theta}_{[-i]})^2)^{3/2}}
$$

onde $\bar{\theta}_{[\cdot]} = \frac{1}{n} \sum_{i=1}^n \hat{\theta}_{[-i]}$.

6. Calcule $\alpha_1$, $\alpha_2$ e os quantis empíricos $\hat{\theta}_{\alpha_1}$ e $\hat{\theta}_{\alpha_2}$ a partir da distribuição ordenada de $\hat{\theta}^{(b)}$.

### Implementação do código

```{r ex3-bca}
ic_bootstrap_bca <- function(x, stat = mean, B = 1000, alpha = 0.05) {
  n <- length(x)
  theta_chapeu <- stat(x)
  
  # bootstrap
  thetas <- replicate(B, stat(sample(x, n, replace = TRUE)))
  
  # jackknife
  jack <- sapply(1:n, function(i) stat(x[-i]))
  theta_barra <- mean(jack)
  
  # parâmetros BCa
  z0 <- qnorm(mean(thetas < theta_chapeu))
  a <- sum((theta_barra - jack)^3) / (6 * (sum((theta_barra - jack)^2))^(3/2))

  z_alfa <- qnorm(c(alpha / 2, 1 - alpha / 2))
  alfa <- pnorm(z0 + (z0 + z_alfa) / (1 - a * (z0 + z_alfa)))
  
  ic <- quantile(thetas, probs = alfa)
  
  return(ic)
}
```

**Comparação com o Pacote `boot`**

### Implementação do código

```{r ex3-boot}
library(boot)
set.seed(123456789)
x <- rnorm(30, mean = 5, sd = 2)

# necessário para "stud"

metricas_boot_student <- function(data, idx) {
  d <- data[idx]
  m <- mean(d)
  se <- sd(d) / sqrt(length(d))
  return(c(mean = m, se = se))
}

# retorna média e erro padrão
boot_obj <- boot(x, statistic = metricas_boot_student, R = 1000, sim = "ordinary", stype = "i")


ic_student <- ic_bootstrap_studentizado(x, stat = mean, B = 500, R = 100)
ic_bca <- ic_bootstrap_bca(x, stat = mean, B = 1000)

# funções do pacote
boot_student <- boot.ci(boot_obj, type = "stud")
boot_bca <- boot.ci(boot_obj, type = "bca")

resultado <- data.frame(
  Metodo = c("Studentizado (manual)",
             "Studentizado (pacote)",
             "BCa (manual)",
             "BCa (pacote)"),
  IC_Inferior = c(
    round(ic_student[1], 4),
    round(as.numeric(boot_student$student[,4]), 4),
    round(ic_bca[1], 4),
    round(boot_bca$bca[,4], 4)
  ),
  IC_Superior = c(
    round(ic_student[2], 4),
    round(as.numeric(boot_student$student[,5]), 4),
    round(ic_bca[2], 4),
    round(boot_bca$bca[,5], 4)
  )
)

kable(resultado)
```

Os resultados ficaram próximos, o que confirma que o código está performando bem.

# QUestão 04

Faça um estudo de Monte Carlo para comparar a probabilidade de cobertura dos intervalos de confiança bootstrap para a média populacional gerando amostras das distribuições Normal e Lognormal. Para as duas distribuições, utilize tamanhos amostrais iguais a 20, 50 e 150. Considere 4 métodos bootstrap de sua escolha para a obtenção dos intervalos de confiança e também compare com a probabilidade de cobertura do intervalo paramétrico com a $t$-Student.

# Questão 05

Compare os bootstraps paramétrico e não paramétrico na estimação do erro padrão de $\bar{X}$ para estimar $E[X]$ quando os dados são gerados da distribuição binomial negativa. No bootstrap paramétrico, assuma que os dados são oriundos da distribuição Poisson para avaliar o efeito da má especificação da distribuição populacional. Utilize 3 valores diferentes para tamanho amostral.

## Solução

O bootstrap não paramétrico estima a distribuição amostral reamostrando a partir da distribuição empírica (com reposição). Já o bootstrap paramétrico assume uma forma paramétrica e simula a partir dessa distribuição estimada.

### Passo a passo

1. Defina os parâmetros da simulação: a distribuição verdadeira (no caso, Binomial Negativa com $r=4$, $p=0.75$) e seus parâmetros, incluindo a variância e o erro padrão verdadeiro. Serão considerados três tamanhos amostrais: $n = 30, 100, 500$.

2. Para cada tamanho amostral e para cada uma das $M = 1000$ iterações, gere uma amostra da Binomial Negativa, calcule o erro padrão via bootstrap não paramétrico, reamostrando a própria amostra, além do erro padrão via bootstrap paramétrico assumindo incorretamente uma outra distribuição (no caso, Poisson).

3. Para cada $n$, guarde os erros padrão verdadeiros, e os estimados pelos métodos BNP e BP e compare.

### Implementação do código

```{r ex5}
M <- 1000
B <- 2000
tamanhos <- c(30, 100, 500) 

r <- 4 
p <- 0.75 

var_x <- r * (1 - p) / (p^2) 

# calcula o erro padrão verdadeiro de X barra
calcula_ep <- function(n) {
  sqrt(var_x / n)
}

ep <- list()

simulacao <- function(tamanho_amostral, M, B, r, p) {
  
  ep_np <- numeric(M) # não paramétrico
  ep_p <- numeric(M) # paramétrico
  
  ep_verdadeiro <- calcula_ep(tamanho_amostral)

  for (i in 1:M) {
    # geração da amostra real
    amostra <- rnbinom(tamanho_amostral, size = r, prob = p)
    
    # não paramétrico
    media_np <- replicate(B, {
      mean(sample(amostra, tamanho_amostral, replace = TRUE))
    })
    ep_np[i] <- sd(media_np)
    
    # paramétrico (mal especificado)
    lambda_chapeu <- mean(amostra)
    
    media_p <- replicate(B, {
      mean(rpois(tamanho_amostral, lambda = lambda_chapeu))
    })
    ep_p[i] <- sd(media_p)
  }
  
  return(data.frame(
    n = tamanho_amostral,
    EP_Verdadeiro = ep_verdadeiro,
    EP_NP = ep_np,
    EP_P = ep_p
  ))
  
}

set.seed(123456789)
for (n in tamanhos) {
  ep[[as.character(n)]] <- simulacao(n, M, B, r, p)
}


dados_plot <- data.frame()
for (n_str in names(ep)) {
  res <- ep[[n_str]]
  n <- res$n[1]  # apenas o valor de n (é constante dentro de cada data.frame)
  ep_real <- res$EP_Verdadeiro[1]
  
  df_np <- data.frame(
    n = factor(n),
    Metodo = "Não-Paramétrico",
    EP_Estimado = res$EP_NP,
    EP_Verdadeiro = ep_real
  )
  
  df_p <- data.frame(
    n = factor(n),
    Metodo = "Paramétrico (ajuste ruim)",
    EP_Estimado = res$EP_P,
    EP_Verdadeiro = ep_real
  )
  
  dados_plot <- rbind(dados_plot, df_np, df_p)
}

ggplot(dados_plot, aes(x = EP_Estimado, fill = Metodo)) +
  geom_density(alpha = 0.6) +
  facet_wrap(~ n, scales = "free_x", labeller = label_both) +
  geom_vline(aes(xintercept = EP_Verdadeiro),
             linetype = "dashed", color = "black") +
  scale_fill_manual(values = c(
    "Não-Paramétrico" = "blue",
    "Paramétrico (ajuste ruim)" = "red"
  )) +
  labs(
    title = "Comparação dos Estimadores de Erro Padrão por Bootstrap",
    subtitle = "Linha tracejada: erro padrão real",
    x = "EP Estimado",
    y = "Densidade"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")
```

O bootstrap não paramétrico apresenta um erro padrão muito próximo do EP verdadeiro em todos os tamanhos amostrais. Ao reamostrar diretamente dos dados, não faz suposições sobre a distribuição (além de i.i.d.) e por isso reflete de forma fiel a variabilidade dos dados amostrais. Já o bootstrap paramétrico subestima o erro padrão em todos os tamanhos amostrais, consequência da má especificação; mesmo com $n$ grande, o método paramétrico mas incorreto leva a uma inferência equivocada.

# Questão 06

Faça uma adaptação da função apresentada no Exemplo 4.11 (apostila em HTML) de tal forma que exista um argumento para definir o tipo de teste (bilateral, unilateral à esquerda ou unilateral à direita). Use um estudo Monte Carlo para estimar a **função poder** em um teste unilateral à esquerda, considerando diferentes tamanhos amostrais e gerando dados da distribuição Exponencial. Utilize o mesmo tamanho amostral para as duas amostras das populações comparadas, fixe o valor esperado da primeira população e altere o valor esperado da segunda população.

# Questão 07

Realize um estudo de Monte Carlo para estimar a função poder do teste de hipóteses bootstrap para a média de uma população e compare com a função poder estimada para o teste $t$ em uma situação em que uma hipótese do teste é violada.

## Solução

### Passo a passo

1. Defina os parâmetros da simulação.

2. Implemente a função do teste bootstrap para a média: centralize a amostra sob $H0$, reamostre $B$ vezes da amostra centrada, calcular a estatística $t^*$ em cada réplica, e calcule o p-valor no bootstrap como proporção de $|t^*| >= |t_{obs}|$. A 

3. Implemente a rotina de Monte Carlo e, para cada $mu$ em uma grade, repita $M$ vezes: gere uma amostra da população (nesse caso, a escolhida que viola a hipótese de normalidade do teste foi $\chi^2$ com graus de liberdade = $mu$), aplique o teste $t$ clássico e o teste bootstrap. Conte as rejeições e estime poder pela proporção.

4. Execute a simulação e avalie a eficiência.

Nesse cenário, as hipóteses são:

$$
\begin{cases}
H_0: \mu = 2 \\
H_1: \mu \neq 2
\end{cases}
$$

### Implementação do código

```{r ex7}
teste_boot <- function(z, mu0, B = 1000) {
  n <- length(z)

  teste_t_obs <- t.test(z, mu = mu0)
  t_obs <- teste_t_obs$statistic
  
  # translação para ter média mu0.
  z_til <- z - mean(z) + mu0
  
  t_estrela <- numeric(B)
  
  for(b in 1:B){
    # amostra centrada em mu0
    z_estrela <- sample(z_til, size = n, replace = TRUE)
    t_estrela[b] <- t.test(z_estrela, mu = mu0)$statistic
  }

  p_valor <- ( sum(t_estrela >= abs(t_obs)) + sum(t_estrela <= -abs(t_obs)) ) / B
  
  return(p_valor)
}

poder_mc <- function(mu_vec, n, M, B, alfa) {
  
  num_mu <- length(mu_vec)
  poder_t <- numeric(num_mu)
  poder_boot <- numeric(num_mu)
  mu0 <- 2
  
  for (i in 1:num_mu) {
    mu_real <- mu_vec[i]
    # Em uma distribuicao Chi-quadrado, E[X] = nu. Entao, nu = mu_real.
    nu_real <- mu_real 
    
    rejeicoes_t <- 0
    rejeicoes_boot <- 0
    
    # Monte Carlo
    for (m in 1:M) {
      dados_mc <- rchisq(n, df = nu_real)
      
      p_valor_t <- t.test(dados_mc, mu = mu0, alternative = "two.sided")
      if (p_valor_t$p.value <= alfa) {
        rejeicoes_t <- rejeicoes_t + 1
      }
      
      p_valor_boot <- teste_boot(dados_mc, mu0 = mu0, B = B)
      if (p_valor_boot <= alfa) {
        rejeicoes_boot <- rejeicoes_boot + 1
      }
    }
    
    poder_t[i] <- rejeicoes_t / M
    poder_boot[i] <- rejeicoes_boot / M
  }
  
  return(data.frame(
    mu_real = mu_vec,
    Poder_T = poder_t,
    Poder_Bootstrap = poder_boot
  ))
}

mu_valores <- c(1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0)
M <- 500
B <- 1000
alfa <- 0.05

set.seed(123456789)

resultados1 <- poder_mc(
  mu_vec = mu_valores,
  n = 30,
  M = M,
  B = B,
  alfa = alfa
)

kable(resultados1)

df_plot1 <- data.frame(
  mu_real = resultados1$mu_real,
  Poder = c(resultados1$Poder_T, resultados1$Poder_Bootstrap),
  Metodo = factor(rep(c("Teste T (Violado)", "Bootstrap"), each = length(mu_valores)))
)

resultados2 <- poder_mc(
  mu_vec = mu_valores,
  n = 100,
  M = M,
  B = B,
  alfa = alfa
)

kable(resultados2)

par(mfrow=c(1,2))

df_plot2 <- data.frame(
  mu_real = resultados2$mu_real,
  Poder = c(resultados2$Poder_T, resultados2$Poder_Bootstrap),
  Metodo = factor(rep(c("Teste T (Violado)", "Bootstrap"), each = length(mu_valores)))
)

ggplot(df_plot1, aes(x = mu_real, y = Poder, color = Metodo)) +
  geom_line(size = 1) +
  geom_point(size = 3) +
  geom_vline(xintercept = 2, linetype = "dashed", color = "black", alpha = 0.7) +
  geom_hline(yintercept = alfa, linetype = "dotted", color = "gray50") +
  scale_y_continuous(limits = c(0, 1)) +
  labs(
    title = "Poder: Teste T vs. Bootstrap (n = 30)",
    subtitle = "População Qui-quadrado",
    x = expression(paste(mu)),
    y = "Poder"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")

ggplot(df_plot2, aes(x = mu_real, y = Poder, color = Metodo)) +
  geom_line(size = 1) +
  geom_point(size = 3) +
  geom_vline(xintercept = 2, linetype = "dashed", color = "black", alpha = 0.7) +
  geom_hline(yintercept = alfa, linetype = "dotted", color = "gray50") +
  scale_y_continuous(limits = c(0, 1)) +
  labs(
    title = "Poder: Teste T vs. Bootstrap (n = 100)",
    subtitle = "População Qui-quadrado",
    x = expression(paste(mu)),
    y = "Poder"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")
```

O método não paramétrico usando bootstrap é melhor nesse caso, uma vez que não depende de hipóteses sobre a distribuição dos dados. A violação de suposição de normalidade tem um grave custo ao teste paramétrico $t$-Student.