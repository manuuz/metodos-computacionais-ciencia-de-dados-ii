---
title: "Lista 3 Métodos Computacionais para Ciência de Dados II"
author: "Emanuelle Oliveira, Maria Luiza Oliveira, Mariana Fleming"
execute: 
  echo: true
  warning: false
  message: false
output:
  pdf_document:
    keep_tex: true
  html_document: default
---
```{r message=FALSE, warning=FALSE, include=FALSE}
library(kableExtra)
```


# Questão 1

Considere $\theta=\int_{0}^{1}e^{x}dx$. Use uma simulação de Monte Carlo para estimar pelo método da variável antitética e também pelo método de Monte Carlo simples. Calcule uma estimativa empírica da redução percentual na variância ao usar a variável antitética.

## Solução

```{r}

```

# Questão 2

Suponha que Y seja uma variável aleatória normal com média 1 e variância 1, e que, condicionalmente a $Y=y$, a variável X seja normal com média y e variância 4. Deseja-se usar simulação para estimar eficientemente $\theta=P\{X>1\}$.

**a) Explique como obter o estimador de simulação de Monte Carlo simples.**

## Solução

**b) Mostre como a esperança condicional pode ser usada para obter um estimador aprimorado.**

## Solução

```{r}

```

**c) Mostre como o estimador do item (b) pode ser ainda mais aprimorado utilizando Y como variável de controle.**

## Solução

```{r}

```

**d) Implemente os três métodos acima e mostre a variabilidade dos estimadores replicando o uso de cada algoritmo 200 vezes.**

## Solução

```{r}

```

# Questão 3

Obtenha uma estimativa de Monte Carlo para $\int_{1}^{\infty}\frac{x^{2}}{\sqrt{2\pi}}e^{-x^{2}/2}dx$ utilizando o método de amostragem por importância (importance sampling).

## Solução

No \textit{Importance Sampling} podemos reescrever a integral alvo ($f(x)$) de uma forma que possamos amostrar de uma distribuição de probabilidade proposta ($g(x)$) da nossa escolha, para isso reescrevemos:

$\int f(x)dx = \int g(x) \frac{f(x)}{g(x)}dx = \int g(x)w(x)dx$ onde $w(x)$ chamamos de peso.

Utilizaremos dessa integral como valor esperado da função $w(x) = \frac{f(x)}{g(x)}$ quando amostrarmos $X$ da proposta $g(x)$:

$I = E_g[w(x)]$

Logo, nosso Monte Carlo para $I$ com $N$ amostras será a média:

$Î = \frac{1}{N}\sum_{i=1}^{N} w(x)$

Temos como alvo $f(x) = \int_{1}^{\infty}\frac{x^{2}}{\sqrt{2\pi}}e^{-x^{2}/2}dx$, que pode ser interpretada como $f(x) = x^2 \cdot \phi(x)$, onde $\phi(x) = \frac{1}{\sqrt{2\pi}}e^{-x^{2}/2}$ é a densidade da Normal Padrão.
Como proposta escolhemos a Normal Truncada no intervalo da integral alvo, $[1, \infty)$, $g(x)=\frac{\phi(x)}{1-\Phi(1)}$, onde o denominador iremos chamar de constante normalizadora $C=1-\Phi(1)$.

Reconstruindo nossa função de peso $w(x)$ teremos:

$w(x) = \frac{f(x)}{g(x)} = \frac{x^2 \cdot \phi(x)}{\frac{\phi(x)}{C}} = C \cdot x^2$

Então teremos nosso estimador de Monte Carlo:

$Î = \frac{1}{N}\sum_{i=1}^{N}C\cdot x_i^2$

Amostra proposta $g(x)$:
```{r amostra-proposta-sir}
dnormtrunc <- function(x, mu=0, sigma=1, a, b){
  d <- dnorm(x, mu, sigma)/( pnorm(b, mu, sigma) - pnorm(a, mu, sigma) )
}

rnormtrunc <- function(n, mu=0, sigma=1, a, b){
  us <- runif(n)
  amostra <- qnorm( pnorm(a, mu, sigma) + 
                      ( pnorm(b, mu, sigma) - pnorm(a, mu, sigma) )*us, mu, sigma )
}

a=1
b=1000000 #Aproximacao de um numero muito grande como "infinito"
amostra_proposta <- rnormtrunc(100000, a=a, b=b)

par(mar = c(4, 4, 1, 1))
hist(amostra_proposta, xlab = expression(x), ylab = "Densidade", prob = T, main = "")
grid <- seq(a, b, by = 0.01)
lines(grid, dnormtrunc(grid, a=a, b=b), col = "red", lwd = 2 )

```

Simulação de Monte Carlo:
```{r monte-carlo-sir}
N <- 100000
C <- 1 - pnorm(1)
amostras_x <- rnormtrunc(n = N, mu = 0, sigma = 1, a = 1, b = Inf)

estimativa_I <- mean(C * amostras_x^2)
valor_exato <- dnorm(1)

tabela <- data.frame(
  Método = c("Estimativa de Monte Carlo", "Valor Analitico"),
  Valor = c(estimativa_I, valor_exato)
)

kable(tabela, caption = "Metodo para Integral")
``` 

# Questão 4

Utilize o algoritmo de Newton-Raphson para estimar os parâmetros de um modelo de regressão Poisson em que $y_{i}\sim Poisson(\lambda=exp\{\beta_{0}+\beta_{1}x_{i}\})$. Gere dados do modelo de regressão e avalie se o algoritmo fornece boas estimativas.

## Solução

```{r}

```

# Questão 5

Implemente um estudo Monte Carlo com $M=100$ réplicas para avaliar o algoritmo EM implementado nos slides para o modelo Poisson inflado de zeros e avalie as estimativas nos 4 cenários apresentados nos slides.

## Solução

```{r}

```

# Questão 6

Implemente o algoritmo EM para mistura de duas distribuições Normais apresentado nos slides e avalie a estimação em 4 cenários alterando tamanho amostral e valores do parâmetros.

## Solução

```{r}

```

# Questão 7

Implemente o algoritmo ECM para mistura de duas distribuições Gamas apresentado nos slides de variantes do algoritmo EM. Avalie as estimativas gerando dados de alguns cenários com mistura de duas gamas.

## Solução

```{r}

```